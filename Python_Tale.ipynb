{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tale\n",
    "## Multilayer RNN for Character Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "    - Overview\n",
    "    - Architecture\n",
    "    - Data\n",
    "    - Code\n",
    "        - Data Generator\n",
    "        - RNN Model\n",
    "        - RNN Char Model\n",
    "    - Predictions\n",
    "    - Future Work\n",
    "    - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "I have created a generalized multilayer RNN for character prediction class that can accept as many files containing text as you want, and will train a RNN of as many layers as you'd like for any length sequence you would like using your choice of LSTM, GRU or ELMAN gates, using your choice of optimizer.  The RNN will be able to generate predictions at the character level, and if trained adequately will be able to generate its own TensorFlow code to writing Shakespeare esque plays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "This architecture was inspired by Karpathy's [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) on the effectiveness of RNNs.  In the post Karpathy outlines how to create a single layer RNN with ELMAN gates to generate a character prediction for every time step.\n",
    "<img src=\"Images/charseq.jpg\">\n",
    "Image Source: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "There are three changes I have made to this architecture:\n",
    "    - I allowed for the LSTM, GRU, or the ELMAN gate to be used\n",
    "        - LSTM's and GRU's allow for the gradient to flow further back in time allowing for better learning and in               \n",
    "          turn better predictions\n",
    "    - I allowed for arbitrary number of layers\n",
    "        - Increasing the number of layers allow for more complexity to be expressed in the weights generating better               \n",
    "          predictions\n",
    "    - I allowed for the number of predictions per sequence to become a hyperparameter\n",
    "        - Changing the predictions from being for every time step to every nth time step ensures a there is a               \n",
    "          minimum context of n characters before a prediction is made allowing for potentially better predictions          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Unfortunately, AWS rejected my request to use a GPU instance.  Therefore, I was forced to use to train my multilayer rnn on cpus.  Due to the significant slowdown from training on cpus I had to cut back significantly on my dataset to be able to train my net in a reasonable amount of time.  For this reason, I could not not train my net on the TensorFlow Github repository as I originally intended and instead I trained my net on Shakespeare's Hamlet.  Hence, the code below is applied to Hamlet, but is generalized so that you are able to run this code on any file containing text.\n",
    "\n",
    "I have generated three plots below showing the most common characters, most common strings of length 20 and most common strings of length 2 for Hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "from itertools import chain\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "class EDA_RNN_Text(object):\n",
    "    \"\"\"\n",
    "    generate exploraty plots for text data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_names: List of Strings; location of the text files that you'd like the RNN to train on\n",
    "    len_sequence: Integer; length of sequence of strings to be generated for plot_top_str\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    data: number of sequences x len_sequence numpy array; matrix where each row is the byte representation\n",
    "                                                          of a len_sequence number of characters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_names, len_sequence=4):\n",
    "        self.file_names = file_names\n",
    "        self.len_sequence = len_sequence\n",
    "        self.data = self.get_data()\n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        takes list of file_names -> grabs text from each file -> converts byte form -> generates sequences\n",
    "        of length length_sequence -> concatenates all sequences into one numpy array\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: number of sequences x len_sequence numpy array; matrix where each row is the byte representation\n",
    "                                                              of a len_sequence number of characters\n",
    "        \"\"\"\n",
    "        def read_file(file_name):\n",
    "            \"\"\"\n",
    "            grabs the text from a document\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            file_name: string; location of a file\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            string; text in the document\n",
    "            \"\"\"\n",
    "            with open(file_name) as f:\n",
    "                return f.read()\n",
    "            \n",
    "        list_files = map(glob.glob, self.file_names)\n",
    "        py_files = reduce(lambda i, j: i+j, list_files)\n",
    "        list_accum = map(read_file, py_files)\n",
    "        la_filter = filter(lambda x: len(x)>0, list_accum)\n",
    "        list_bytes = map(lambda i: map(ord,i), la_filter)\n",
    "        list_list_bytes = map(lambda x: [x[i:i+self.len_sequence] for i in range(0,len(x)-self.len_sequence+1)]\n",
    "                              ,list_bytes)\n",
    "        data = np.array(list(chain.from_iterable(list_list_bytes)))#http://stackoverflow.com/questions/35004945/python-pandas-reduce-function-for-series\n",
    "        return data\n",
    "        \n",
    "    def plot_top_char(self, top_number = 50):\n",
    "        \"\"\"\n",
    "        barplot for the top_number characters with the largest counts\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        top_number: Integer; number of characters with the highest count to plot\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None; produces barplot for the top_number characters with the largest counts                                                              \n",
    "        \"\"\"\n",
    "        ll = list(chain(*self.data))\n",
    "        mm = Counter(ll)\n",
    "        most_com = mm.most_common(top_number)\n",
    "        char = map(chr,[i[0] for i in most_com])\n",
    "        plt.figure(figsize = (15,15))\n",
    "        sb.barplot(char,[i[1] for i in most_com])\n",
    "        plt.title(\"Top %s Characters\"%(top_number))\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_top_str(self, top_number = 30):\n",
    "        \"\"\"\n",
    "        barplot for the top_number strings of length len_sequence with the largest counts\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        top_number: Integer; number of strings with the highest count to plot\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None; produces barplot for the top_number strings of length len_sequence with the largest counts \n",
    "        \"\"\"\n",
    "        list_n = map(lambda i: list(self.data[i]), range(self.data.shape[0]))\n",
    "        str_n = map(lambda i: \",\".join(map(str,i)),list_n)\n",
    "        dict_n = Counter(str_n)\n",
    "        top_list = dict_n.most_common(top_number)\n",
    "        top_str = map(lambda j: ''.join(map(lambda i: chr(int(i)),j[0].split(\",\"))), top_list)\n",
    "        plt.figure(figsize = (15,15))\n",
    "        sb.barplot(top_str, [i[1] for i in top_list])\n",
    "        plt.title(\"Top %s Strings of Length %s\"%(top_number,self.len_sequence))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ert = EDA_RNN_Text([\"Data/shakespeare-hamlet.txt\"], len_sequence= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAANwCAYAAACWCnMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElqQ/8ftokp88OV9AgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a90fb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ert.plot_top_char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAOaCAYAAAD6buHmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15df85d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ert.plot_top_str(top_number=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAANwCAYAAABu6ojXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkyRJkqRGWOAkSZIkqRH/A49do+uc+BFSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100735d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EDA_RNN_Text([\"Data/shakespeare-hamlet.txt\"],\n",
    "             len_sequence= 2).plot_top_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "The code is broken up into three parts\n",
    "    \n",
    "    1) Data Generator - creates a test train split on the data and a data generator to ensure the model gets every            \n",
    "                        observation once for each epoch\n",
    "    2) RNN Model - creates a multilayer RNN composed with the type of gates specified by the user in TensorFlow\n",
    "    3) RNN Char Model - combines the Data Generator and RNN Model to train the multilayer rnn and makes character                             \n",
    "                        level predictions based on the multilayer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generator\n",
    "\n",
    "Creates a test train split on the data and a data generator to ensure the model gets every observation once for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "class RNN_Text_Generator(object):\n",
    "    \"\"\"\n",
    "    Data generator for text data to be input for a RNN.\n",
    "    Creates a test-train split of the data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_names : list of strings; location of the text files that you'd like the RNN to train on\n",
    "    len_sequence: integer; length of sequence for the RNN where len_sequence - 1 elements are input to\n",
    "                           the RNN and the last element is the target output of the RNN\n",
    "    mini_batch_size: integer; number of elements to include for each minibatch produced by the\n",
    "                              data_generator function\n",
    "    test_train_split: float; percent of data you want to use for the training set\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    data: number of sequences x len_sequence numpy array; matrix where each row is the byte representation\n",
    "                                                          of a len_sequence number of characters\n",
    "    len_data: integer; total number of sequences in the dataset\n",
    "    mini_batch_index: integer; counter used to keep track which subset of the data to send for the next call of\n",
    "                               data_generator\n",
    "    mn: integer; smallest byte value observed in the data\n",
    "    mx: integer; largest byte value observed in the data\n",
    "    train_num: integer; number of training observations\n",
    "    train_range: list of integers; list containing all values between 0 and train_num-1 inclusively\n",
    "    x_test: numpy array; test input for the RNN in byte form\n",
    "    x_train: numpy array; training input for the RNN in byte form\n",
    "    y_test: numpy array; test target ouput for the RNN in byte form\n",
    "    y_train: numpy array; training target ouput for the RNN in byte form                          \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_names, len_sequence = 10,pred_len = 2, mini_batch_size = 200, test_train_split = .7):\n",
    "        self.file_names = file_names\n",
    "        self.pred_len = pred_len\n",
    "        self.len_sequence = len_sequence\n",
    "        self.test_train_split = test_train_split\n",
    "        self.x, self.y, self.mn, self.mx = self.get_data()\n",
    "        self.len_data = len(self.x)\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test, self.train_num = self.split_data()\n",
    "        self.train_range = range(self.train_num)\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.mini_batch_index = 0\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        takes list of file_names -> grabs text from each file -> converts byte form -> generates sequences\n",
    "        of length length_sequence -> concatenates all sequences into one numpy array\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: number of sequences x len_sequence numpy array; matrix where each row is the byte representation\n",
    "                                                              of a len_sequence number of characters\n",
    "        mn: integer; smallest byte value observed in the data\n",
    "        mx: integer; largest byte value observed in the data\n",
    "        \"\"\"\n",
    "        def read_file(file_name):\n",
    "            \"\"\"\n",
    "            grabs the text from a document\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            file_name: string; location of a file\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            string; text in the document\n",
    "            \"\"\"\n",
    "            with open(file_name) as f:\n",
    "                return f.read()\n",
    "            \n",
    "        list_files = map(glob.glob, self.file_names)\n",
    "        py_files = reduce(lambda i, j: i+j, list_files)\n",
    "        list_accum = map(read_file, py_files)\n",
    "        la_filter = filter(lambda x: len(x)>0, list_accum)\n",
    "        list_bytes = map(lambda i: map(ord,i), la_filter)\n",
    "        mn = min(map(lambda i: min(i), list_bytes))\n",
    "        mx = max(map(lambda i: max(i), list_bytes))\n",
    "        list_list_bytes = map(lambda x: [(x[i:i+self.len_sequence],map(lambda j: x[j],range(i+self.pred_len,i+self.pred_len+self.len_sequence,self.pred_len))) for i in range(0,len(x)-self.len_sequence-self.pred_len+1)]\n",
    "                              ,list_bytes)\n",
    "        concat_l = list(chain.from_iterable(list_list_bytes))\n",
    "        list_x = [i[0] for i in concat_l]\n",
    "        list_y = [i[1] for i in concat_l]\n",
    "        x,y = np.array(list_x),np.array(list_y)#http://stackoverflow.com/questions/35004945/python-pandas-reduce-function-for-series\n",
    "        return x,y, mn, mx\n",
    "    \n",
    "    def split_data(self):\n",
    "        \"\"\"\n",
    "        Splits the data into the train and test sets then splits the inputs from the output\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        x_train: numpy array; training input for the RNN in byte form\n",
    "        y_train: numpy array; training target ouput for the RNN in byte form\n",
    "        x_test: numpy array; test input for the RNN in byte form\n",
    "        y_test: numpy array; test target ouput for the RNN in byte form\n",
    "        train_num: integer; number of training observations\n",
    "        \"\"\"\n",
    "        rng = np.array(range(self.len_data))\n",
    "        np.random.shuffle(rng)\n",
    "        train_num = int(self.test_train_split*self.len_data)\n",
    "        train_index, test_index = rng[:train_num], rng[train_num:]\n",
    "        x_train, y_train, x_test, y_test = self.x[train_index], self.y[train_index], self.x[test_index], self.y[test_index]\n",
    "        return x_train, y_train, x_test, y_test, train_num\n",
    "    \n",
    "    def one_hot_map(self,lst):\n",
    "        \"\"\"\n",
    "        takes a list of bytes -> create one hot encoded vector for each byte -> concatenate all byte vectors\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lst: list of integers; list of length length_seq containing the byte reprsentation for each char in the\n",
    "                               sequence\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        numpy array; contains the matrix of one hot encoded characters\n",
    "        \"\"\"\n",
    "        def one_hot_char(num):\n",
    "            \"\"\"\n",
    "            one hot encodes each character based on its byte representation\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            num: integer; byte representation for a given character\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            z: numpy array; the one hot encoding for the given character's byte representation\n",
    "            \"\"\"\n",
    "            num_adj = num - self.mn \n",
    "            z = np.zeros((1,self.mx - self.mn + 1))\n",
    "            z[0,num_adj] = 1.0\n",
    "            return z\n",
    "        lst_one_hot = map(one_hot_char,lst)\n",
    "        return np.vstack(lst_one_hot)\n",
    "    \n",
    "    def data_generator(self):\n",
    "        \"\"\"\n",
    "        data generator for RNN produces a minibatch tensor of input and the corresponding output numpy array\n",
    "        data generator will not pass the same observation until all other observations have been returned\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        x_mb: 3 dimensional numpy array; minibatch of training input data\n",
    "        y_mb: 2 dimensional numpy array; minibatch of training output data\n",
    "        \"\"\"\n",
    "        min_index = self.mini_batch_index * self.mini_batch_size % self.train_num \n",
    "        if(min_index+self.mini_batch_size>= self.train_num):\n",
    "            max_rng = np.array(range(min_index,self.train_num))\n",
    "            add_num = self.mini_batch_size-len(max_rng)\n",
    "            add_idx = np.random.choice(range(self.train_num), size = add_num, replace = False)\n",
    "            idx_stack = np.hstack([max_rng,add_idx])\n",
    "            xt = self.x_train[idx_stack]\n",
    "            yt = self.y_train[idx_stack]\n",
    "        else:\n",
    "            max_index = min_index+self.mini_batch_size\n",
    "            xt = self.x_train[min_index:max_index]\n",
    "            yt = self.y_train[min_index:max_index]\n",
    "        self.mini_batch_index+=1\n",
    "        x_mb = np.vstack(map(self.one_hot_map,xt)).reshape(self.mini_batch_size, self.len_sequence, self.mx-self.mn+1)\n",
    "        y_mb = np.vstack(map(self.one_hot_map,yt)).reshape(self.mini_batch_size, self.len_sequence/self.pred_len, self.mx-self.mn+1)\n",
    "        return x_mb, y_mb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Model\n",
    "\n",
    "Creates a multilayer RNN composed with the type of gates specified by the user in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN_Model(object):\n",
    "    \"\"\"\n",
    "    creates a multilayer rnn model with either Elman, GRU or LSTM gates in TensorFlow \n",
    "    based on parameters passed by user\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h_size: integer; size of the hidden layer\n",
    "    input_size: integer; size of the input layer\n",
    "    n_layers: integer; number of layers for the RNN\n",
    "    act: TensorFlow activation function; activation function to use for an Elman net\n",
    "    classification: Boolean; True -> Produce a classification RNN\n",
    "                             False -> Produce a regression RNN\n",
    "    final_step: String; type of prediction you'd like to make:\n",
    "                                                               \"last\" -> use only the last output from last time step\n",
    "                                                                         to make prediction\n",
    "                                                                other -> use output from all time steps to make \n",
    "                                                                         predictions\n",
    "    gate: String; type of gate function you want used for RNN either \"ELMAN\", \"GRU\" or \"LSTM\"\n",
    "    optimizer: TensorFlow optimization function; optimizer to be used to train the RNN\n",
    "    pred_len: Integer; make a prediction at the pred_len time step\n",
    "    target_size: Integer or None; size of the prediction if None it will be equal to input_size\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    gate_func: function; gate function you want used for RNN either f_ELMAN, f_GRU or f_LSTM                       \n",
    "    \"\"\"\n",
    "    def __init__(self, h_size, input_size, n_layers, act = tf.nn.relu, classification= True, final_step = \"last\", \n",
    "                 gate = \"LSTM\", mini_batch_size = 200,optimizer = tf.train.AdamOptimizer(), pred_len = 2, target_size = None):\n",
    "        gate_dict = {\"LSTM\": self.f_LSTM, \"GRU\": self.f_GRU, \"ELMAN\": self.f_ELMAN}\n",
    "        self.h_size = h_size\n",
    "        self.input_size = input_size\n",
    "        self.n_layers = n_layers\n",
    "        self.optimizer = optimizer\n",
    "        self.pred_len = 2\n",
    "        self.act = act\n",
    "        self.classification = classification\n",
    "        self.final_step = final_step\n",
    "        self.gate = gate\n",
    "        self.gate_func = gate_dict[gate]\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        if target_size is None:\n",
    "            self.target_size = input_size\n",
    "        else:\n",
    "            self.target_size = target_size\n",
    "        \n",
    "    def generate_model(self):\n",
    "        \"\"\"\n",
    "        creates a multilayer RNN model based on the parameters used to instantiate the class\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        inputs: TensorFlow Placeholder; placeholder for the data to be used as the input layer\n",
    "        y: TensorFlow Placeholder; placeholder for the target output\n",
    "        initial_hidden: TensorFlow Placeholder; placeholder for the data to be used as hidden \n",
    "                                                layer data for time step 0\n",
    "        train_step: Tensor action produces Null; action that will train the RNN \n",
    "                                                 REQUIRES: inputs, y, initial_hidden specified in the feed_dict\n",
    "        accuracy: Tensor action produces double; action that will produce the accuracy for the data passed into the RNN\n",
    "                                                 REQUIRES: inputs, y, initial_hidden specified in the feed_dict\n",
    "        y_hat: Tensor action produces array; action produce the prediction(s) of the RNN for the data passed into the RNN\n",
    "                                                 REQUIRES: inputs, initial_hidden specified in the feed_dict\n",
    "        tf.train.Saver(); instance used to either save the TensorFlow session or upload a saved TensorFlow session\n",
    "        \"\"\"\n",
    "        inputs = tf.placeholder(tf.float32, shape=[self.mini_batch_size,None, self.input_size], name = 'inputs')\n",
    "        inputs_ = tf.transpose(inputs, perm = [1, 0, 2])\n",
    "        if self.gate == \"LSTM\":\n",
    "            initial_hidden = tf.placeholder(tf.float32, shape = [None, 2*self.n_layers*self.h_size])\n",
    "        else:\n",
    "            initial_hidden = tf.placeholder(tf.float32, shape = [None, self.n_layers*self.h_size])\n",
    "        y = tf.placeholder(tf.float32, shape=[self.mini_batch_size,None,  self.target_size], name = \"y\")\n",
    "        \n",
    "        if self.final_step == \"last\":\n",
    "            final_step_func = self.last_final_step()\n",
    "        else:\n",
    "            final_step_func = self.multi_final_step()\n",
    "        \n",
    "        multi_layer = self.multi_layer_general(self.input_size)\n",
    "        all_hidden_states = tf.scan(multi_layer, inputs_, initializer = initial_hidden, name = \"LSTM_H\")\n",
    "        loss, y_hat, _ = final_step_func(all_hidden_states,y)\n",
    "        train_step = self.optimizer.minimize(loss)\n",
    "        correct_pred = tf.equal(tf.argmax(y_hat,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        return inputs, y, initial_hidden, train_step, accuracy, y_hat, all_hidden_states, tf.train.Saver()\n",
    "\n",
    "    def f_ELMAN(self, i_size, name_scope = \"gru_recursion\", sd = .01):\n",
    "        \"\"\"\n",
    "        generates a single layer of an Elman net\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i_size: Integer; input size for the given layer of the Elman net\n",
    "        name_scope: String; the name scope to be passed to tf.name_scope\n",
    "        sd: Double; standard deviation used to initialize the weight matricies and vector \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fR: function; function to perform the actions of a single layer of an Elman net\n",
    "        \"\"\"\n",
    "        with tf.name_scope(name_scope) as scope:\n",
    "            W = tf.Variable(tf.truncated_normal([i_size, self.h_size], stddev = sd), name = \"W\")\n",
    "            U = tf.Variable(tf.truncated_normal([self.h_size, self.h_size], stddev = sd), name = \"U\")\n",
    "            b = tf.Variable(tf.zeros([self.h_size]), name = \"b\") \n",
    "            def fR(stateTm1, x):\n",
    "                \"\"\"\n",
    "                performs Elman gate operation on given weights and inputs\n",
    "        \n",
    "                Parameters\n",
    "                ----------\n",
    "                stateTm1: TensorFlow Vector; output from hidden state at previous time step\n",
    "                x: TensorFlow Vector; input vector at same time step\n",
    "\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                TensorFlow vector; result of performing Elman gate operation on given weights and inputs\n",
    "                \"\"\"\n",
    "                return self.act(tf.matmul(x, W) + tf.matmul(stateTm1, U) + b)\n",
    "\n",
    "            return fR    \n",
    "\n",
    "\n",
    "    def f_GRU(self, i_size, name_scope = \"gru_recursion\", sd = .01):\n",
    "        \"\"\"\n",
    "        generates a single layer of a GRU net\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i_size: Integer; input size for the given layer of the Elman net\n",
    "        name_scope: String; the name scope to be passed to tf.name_scope\n",
    "        sd: Double; standard deviation used to initialize the weight matricies and vector \n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fR: function; function to perform the actions of a single layer of an GRU net\n",
    "        \"\"\"\n",
    "        def generate_variable_names(i):\n",
    "            \"\"\"\n",
    "            generate all variable names for given type of weight\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            i: String; type of weight\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            [i+\"_\"+j for j in list_stages]; list of all variable names for given weight type\n",
    "            \"\"\"\n",
    "            list_stages = [\"z\", \"r\", \"h\"]\n",
    "            return [i+\"_\"+j for j in list_stages]\n",
    "\n",
    "        weight_prefixes = [\"W\", \"U\", \"b\"]\n",
    "        W_list, U_list, b_list = map(lambda i: generate_variable_names(i), weight_prefixes)\n",
    "\n",
    "        with tf.name_scope(name_scope) as scope:\n",
    "            W_dictionary = {i : tf.Variable(tf.truncated_normal([i_size, self.h_size], stddev = sd), name = i)\n",
    "                                for i in W_list}\n",
    "            U_dictionary = {i : tf.Variable(tf.truncated_normal([self.h_size, self.h_size], stddev = sd), name = i)\n",
    "                                for i in U_list}\n",
    "            b_dictionary = {i : tf.Variable(tf.zeros([self.h_size]), name = i) for i in b_list}\n",
    "\n",
    "            def fR(stateTm1, x):\n",
    "                \"\"\"\n",
    "                performs GRU gate operations on given weights and inputs\n",
    "        \n",
    "                Parameters\n",
    "                ----------\n",
    "                stateTm1: TensorFlow Vector; output from hidden state at previous time step\n",
    "                x: TensorFlow Vector; input vector at same time step \n",
    "\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                TensorFlow vector; result of performing GRU gate operations on given weights and inputs\n",
    "                \"\"\"\n",
    "                def activate_affine(typ, act, mult):\n",
    "                    \"\"\"\n",
    "                    perform affine transformation and then activation function for the given step of the GRU gate\n",
    "        \n",
    "                    Parameters\n",
    "                    ----------\n",
    "                    typ: String; the step of the GRU gate being performed\n",
    "                    act: TensorFlow activaton function; the activation function to be performed on \n",
    "                                                        the affine transformation\n",
    "                    mult: Integer of TensorFlow vector; value to multiply the matrix multiplication of hidden state\n",
    "                                                        and its weight by, exists for the h step\n",
    "\n",
    "                    Returns\n",
    "                    -------\n",
    "                    returns the vector produced by performing the activation on the affine transformation for the given\n",
    "                    GRU step\n",
    "                    \"\"\"\n",
    "                    return act(tf.matmul(x, W_dictionary[\"W_\"+typ])+(mult*tf.matmul(h, U_dictionary[\"U_\"+typ]))+\n",
    "                                   b_dictionary[\"b_\"+typ])\n",
    "\n",
    "                h = stateTm1\n",
    "                z = activate_affine(\"z\", tf.sigmoid, 1)\n",
    "                r = activate_affine(\"r\", tf.sigmoid, 1)\n",
    "                h_prime = activate_affine(\"h\", tf.nn.tanh, r)\n",
    "                ht = z*h + (1-z)*h_prime\n",
    "                return ht\n",
    "            return fR\n",
    "    \n",
    "    def f_LSTM(self, i_size, name_scope = \"lstm_recursion\", sd = .01):\n",
    "        \"\"\"\n",
    "        generates a single layer of a LSTM net\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i_size: Integer; input size for the given layer of the Elman net\n",
    "        name_scope: String; the name scope to be passed to tf.name_scope\n",
    "        sd: Double; standard deviation used to initialize the weight matricies and vector \n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fR: function; function to perform the actions of a single layer of an LSTM net\n",
    "        \"\"\"\n",
    "        def generate_variable_names(i):\n",
    "            \"\"\"\n",
    "            generate all variable names for given type of weight\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            i: String; type of weight\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            [i+\"_\"+j for j in list_stages]; list of all variable names for given weight type\n",
    "            \"\"\"\n",
    "            list_stages = [\"i\", \"f\", \"o\", \"c\"]\n",
    "            return [i+\"_\"+j for j in list_stages]\n",
    "\n",
    "        weight_prefixes = [\"W\", \"U\", \"b\"]\n",
    "        W_list, U_list, b_list = map(lambda i: generate_variable_names(i), weight_prefixes)\n",
    "\n",
    "        with tf.name_scope(name_scope) as scope:\n",
    "            W_dictionary = {i : tf.Variable(tf.truncated_normal([i_size, self.h_size], stddev = sd), name = i)\n",
    "                                for i in W_list}\n",
    "            U_dictionary = {i : tf.Variable(tf.truncated_normal([self.h_size, self.h_size], stddev = sd), name = i)\n",
    "                                for i in U_list}\n",
    "            b_dictionary = {i : tf.Variable(tf.zeros([self.h_size]), name = i) for i in b_list}\n",
    "\n",
    "            def fR(stateTm1, x):\n",
    "                \"\"\"\n",
    "                performs LSTM gate operations on given weights and inputs\n",
    "        \n",
    "                Parameters\n",
    "                ----------\n",
    "                stateTm1: TensorFlow Vector; contains h and c vectors from the hidden state at previous time step \n",
    "                x: TensorFlow Vector; input vector at same time step \n",
    "\n",
    "\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                TensorFlow vector; result of performing LSTM gate operations on given weights and inputs\n",
    "                \"\"\"\n",
    "                def activate_affine(typ, act):\n",
    "                    \"\"\"\n",
    "                    perform affine transformation and then activation function for the given step of the LSTM gate\n",
    "        \n",
    "                    Parameters\n",
    "                    ----------\n",
    "                    typ: String; the step of the LSTM gate being performed\n",
    "                    act: TensorFlow activaton function; the activation function to be performed on \n",
    "                                                        the affine transformation\n",
    "                    mult: Integer of TensorFlow vector; value to multiply the matrix multiplication of hidden state\n",
    "                                                        and its weight by, exists for the h step\n",
    "\n",
    "                    Returns\n",
    "                    -------\n",
    "                    returns the vector produced by performing the activation on the affine transformation for the given\n",
    "                    LSTM step\n",
    "                    \"\"\"\n",
    "                    return act(tf.matmul(x, W_dictionary[\"W_\"+typ])+tf.matmul(h, U_dictionary[\"U_\"+typ])+\n",
    "                                   b_dictionary[\"b_\"+typ])\n",
    "\n",
    "                h, c = tf.split(1, 2, stateTm1)\n",
    "                list_computations = [(\"i\", tf.sigmoid), (\"f\", tf.sigmoid), (\"o\", tf.sigmoid), (\"c\", tf.nn.tanh)]\n",
    "                i, f, o, c_squig = map(lambda (i, j): activate_affine(i, j), list_computations)\n",
    "                ct = f*c + i*c_squig\n",
    "                ht = o*tf.nn.tanh(ct)\n",
    "                return tf.concat(1, [ht, ct])\n",
    "            return fR\n",
    "        \n",
    "    def multi_layer_general(self, i_size):\n",
    "        \"\"\"\n",
    "        generates a multilayer RNN composed of the type of gated functions specified by the class instantiation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i_size: integer; input size for the RNN\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fR: function; returns function to perform the actions of multilayer RNN composed of the type of gated \n",
    "                      functions specified by the class instantiation\n",
    "        \"\"\"\n",
    "        name_spaces = [\"Recursion_\"+str(i) for i in xrange(self.n_layers)]\n",
    "        layers = [self.gate_func(i_size, name_spaces[0])]+[self.gate_func(self.h_size, name_spaces[i]) for i in range(1, self.n_layers)]\n",
    "\n",
    "        def fR(stateTm1, x):\n",
    "            \"\"\"\n",
    "            performs the actions of multilayer RNN composed of the type of gated functions specified by \n",
    "            the class instantiation\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            stateTm1: TensorFlow Vector; output from hidden state at previous time step for all n_layers\n",
    "            x: TensorFlow Vector; input vector at same time step\n",
    "\n",
    "\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            state_list: TensorFlow Vector; concatenation of output vectors for each layer\n",
    "            \"\"\"\n",
    "            h_list = tf.split(1, self.n_layers, stateTm1)\n",
    "            new_state = layers[0](h_list[0],x)\n",
    "            state_list = new_state\n",
    "            for i in range(1, self.n_layers):\n",
    "                if self.gate == \"LSTM\":\n",
    "                    new_h, _ = tf.split(1, 2, new_state)\n",
    "                else:\n",
    "                    new_h = new_state\n",
    "                new_state = layers[i](h_list[i],new_h)\n",
    "                state_list = tf.concat(1,[state_list, new_state])\n",
    "            return state_list\n",
    "        return fR\n",
    "        \n",
    "    def last_final_step(self):\n",
    "        \"\"\"\n",
    "        creates a function that takes the output at the last time step from the rnn \n",
    "        performs an affine transformation producing the prediction for the rnn and calculates the loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        final_step_func: function; generates function that takes the output at the last time step from the rnn\n",
    "                                   performs an affine transformation producing the prediction for the rnn and\n",
    "                                   calculates the loss\n",
    "        \"\"\"\n",
    "        W_last = tf.Variable(tf.truncated_normal([self.h_size, self.target_size], mean = 0, stddev = 0.01),\n",
    "                                                                                              name = \"W_last\")\n",
    "        b_last = tf.Variable(tf.truncated_normal([self.target_size], mean = 0, stddev = 0.01), name = \"b_last\")\n",
    "            \n",
    "        def final_step_func(all_hidden_states,y):\n",
    "            \"\"\"\n",
    "            produces the prediction for the rnn and calculates the loss\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            all_hidden_states: TensorFlow Vector; contains all output from each time step from the rnn\n",
    "            y: TensorFlow matrix; the target ouputs for the rnn\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            l: Double; the loss of the rnn for the given data\n",
    "            y_hat: matrix; all the predictions for the given data\n",
    "            \"\"\"\n",
    "            last_hidden_state = tf.reverse(all_hidden_states, [True, False, False])[0, :, :]\n",
    "            if self.gate == \"LSTM\":\n",
    "                lay = tf.split(1,2*self.n_layers,last_hidden_state)\n",
    "                last_h = lay[-2]\n",
    "            else:\n",
    "                lay = tf.split(1,self.n_layers,last_hidden_state)\n",
    "                last_h = lay[-1]\n",
    "            affine_transform = tf.matmul(last_h, W_last) + b_last\n",
    "            if self.classification:\n",
    "                y_hat = tf.nn.softmax(affine_transform)\n",
    "                l = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_hat))) \n",
    "            else:\n",
    "                y_hat = affine_transform\n",
    "                l = tf.sqrt(tf.reduce_mean(tf.reduce_sum((y-y_hat)**2.0)))\n",
    "            return l, y_hat, last_h         \n",
    "        return final_step_func\n",
    "    \n",
    "    def multi_final_step(self):\n",
    "        \"\"\"\n",
    "        creates a function that takes the output at each time step(where time step %pred_len ==0) from the rnn \n",
    "        performs an affine transformation producing the predictions for the rnn and calculates the loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        final_step_func: function; generates function that takes the outputat each time step\n",
    "                                   (where time step %pred_len ==0)  from the rnn performs an affine\n",
    "                                   transformation producing the prediction for the rnn and\n",
    "                                   calculates the loss\n",
    "        \"\"\"\n",
    "        W_last = tf.Variable(tf.truncated_normal([self.h_size, self.target_size], mean = 0, stddev = 0.01),\n",
    "                                                                                              name = \"W_last\")\n",
    "        b_last = tf.Variable(tf.truncated_normal([self.target_size], mean = 0, stddev = 0.01), name = \"b_last\")\n",
    "            \n",
    "        def final_step_func(all_hidden_states,y):\n",
    "            \"\"\"\n",
    "            produces the predictions for the rnn and calculates the loss\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            all_hidden_states: TensorFlow Vector; contains all output from each time step from the rnn\n",
    "            y: TensorFlow matrix; the target ouputs for the rnn\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            l: Double; the loss of the rnn for the given data\n",
    "            y_hat: tensor; all the predictions for the given data\n",
    "            \"\"\"\n",
    "            last_hidden_state = tf.reverse(all_hidden_states, [True, False, False])[::self.pred_len, :, :][::-1,:,:]\n",
    "            #last_hidden_state = [tf.reverse(all_hidden_states, [True, False, False])[i, :, :] for i in range(0,len_seq,self.pred_len)]\n",
    "            if self.gate == \"LSTM\":\n",
    "                last_h = tf.split(2,2*self.n_layers,last_hidden_state)[-1]\n",
    "            else:\n",
    "                last_h = tf.split(2,self.n_layers,last_hidden_state)[-1]\n",
    "            affine_transform = tf.einsum(\"ijk,kl->ijl\",last_h, W_last) + b_last \n",
    "            if self.classification:\n",
    "                logit = tf.nn.softmax(affine_transform)\n",
    "                y_hat = tf.transpose(logit,[1,0,2])\n",
    "                l = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_hat)))\n",
    "            else:\n",
    "                y_hat = tf.transpose(logit,[1,0,2])\n",
    "                l = tf.sqrt(tf.reduce_mean(tf.reduce_sum((y[i]-y_hat[i])**2.0)))\n",
    "            return l, y_hat, last_h         \n",
    "        return final_step_func        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Char Model\n",
    "\n",
    "Combines the Data Generator and RNN Model to train the multilayer rnn and makes character level predictions based on the multilayer RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN_Next_Char(object):\n",
    "    \"\"\"\n",
    "    Creates a multi-layer RNN with the type of gate specified to predict the next character\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_names : list of strings; location of the text files that you'd like the RNN to train on\n",
    "    h_size: integer; size of the hidden layer\n",
    "    n_layers: integer; number of layers for the RNN\n",
    "    act: TensorFlow activation function; activation function to use for an Elman net\n",
    "    final_step: String; type of prediction you'd like to make:\n",
    "                                                               \"last\" -> use only the last output from last time step\n",
    "                                                                         to make prediction\n",
    "                                                                other -> use output from all time steps to make \n",
    "                                                                         predictions\n",
    "    gate: String; type of gate function you want used for RNN either \"ELMAN\", \"GRU\" or \"LSTM\"\n",
    "    len_sequence: integer; length of sequence for the RNN where len_sequence - 1 elements are input to\n",
    "                           the RNN and the last element is the target output of the RNN\n",
    "    mini_batch_size: integer; number of elements to include for each minibatch produced by the\n",
    "                              data_generator function\n",
    "    optimizer: TensorFlow optimization function; optimizer to be used to train the RNN\n",
    "    pred_len: Integer; make a prediction at the pred_len time step\n",
    "    test_train_split: float; percent of data you want to use for the training set\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    rnn_tg: instance of RNN_Text_Generator; Data generator for text data to be input for a RNN. \n",
    "            Creates a test-train split of the data.\n",
    "    model: instance of RNN_Model; creates a multilayer rnn model with either Elman, GRU or LSTM \n",
    "                                  gates in TensorFlow based on parameters passed by user\n",
    "    sess_list: list; holds the location of all the models that were checkpointed \n",
    "    \"\"\"\n",
    "    def __init__(self, file_names, h_size, n_layers, act = tf.nn.relu, final_step = \"multi\", \n",
    "                 gate = \"LSTM\", len_sequence = 10, mini_batch_size = 200,\n",
    "                 optimizer = tf.train.AdamOptimizer(), pred_len=2, test_train_split = .7):\n",
    "        self.rnn_tg = RNN_Text_Generator(file_names, len_sequence, pred_len, mini_batch_size,test_train_split)\n",
    "        self.model = RNN_Model(h_size, self.rnn_tg.mx-self.rnn_tg.mn+1, n_layers, act, final_step= final_step,\n",
    "                               gate= gate, mini_batch_size = mini_batch_size, optimizer= optimizer, pred_len = pred_len)\n",
    "        self.pred_len = pred_len\n",
    "        self.sess_list = []\n",
    "        \n",
    "    \n",
    "    def train(self, sess_directory, epochs = 10):\n",
    "        \"\"\"\n",
    "        trains the multilayer rnn\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sess_directory: String; location where you want the checkpointed models to be saved to\n",
    "        epochs: Integer; Number of times you want to iterate through all the data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Null; Model is checkpointed after each epoch and the locations of each checkpoint is stored in sess_list\n",
    "        \"\"\"\n",
    "        tf.reset_default_graph()\n",
    "        inputs, y, initial_hidden, train_step, accuracy, y_hat, _, saver = self.model.generate_model()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            \n",
    "            num_inner = self.rnn_tg.train_num/self.rnn_tg.mini_batch_size\n",
    "            tst_size = self.rnn_tg.y_test.shape[0]\n",
    "                \n",
    "            for e in range(epochs):\n",
    "                for i in range(num_inner):#num_inner\n",
    "                    x_train, y_train = self.rnn_tg.data_generator()\n",
    "                    if self.model.gate == \"LSTM\":\n",
    "                        i_hid = np.zeros([x_train.shape[0], 2*self.model.n_layers*self.model.h_size])\n",
    "                    else:\n",
    "                        i_hid = np.zeros([x_train.shape[0], self.model.n_layers*self.model.h_size])\n",
    "                    ts = sess.run([train_step], {inputs: x_train, y: y_train, initial_hidden: i_hid})\n",
    "                model_location = sess_directory+\"model_epoch_%s.ckpt\"%(e)\n",
    "                self.sess_list.append(model_location)\n",
    "                saver.save(sess,model_location)\n",
    "                test_mb = np.random.choice(range(tst_size), size = self.rnn_tg.mini_batch_size, replace = False)\n",
    "                test_x_mb = np.vstack(map(self.rnn_tg.one_hot_map,self.rnn_tg.x_test[test_mb])).reshape(self.rnn_tg.mini_batch_size, \n",
    "                                                                                     self.rnn_tg.len_sequence, self.rnn_tg.mx-self.rnn_tg.mn+1)\n",
    "                test_y_mb = np.vstack(map(self.rnn_tg.one_hot_map,self.rnn_tg.y_test[test_mb])).reshape(self.rnn_tg.mini_batch_size, \n",
    "                                                                                     self.rnn_tg.len_sequence/self.rnn_tg.pred_len, self.rnn_tg.mx-self.rnn_tg.mn+1)\n",
    "                print \"epoch number %s\"%e\n",
    "                print \"train accuracy: %s\"%sess.run([accuracy], {inputs: x_train, y: y_train, initial_hidden: i_hid})\n",
    "                print \"test accuracy: %s\"%sess.run([accuracy], {inputs: test_x_mb, y: test_y_mb,initial_hidden: i_hid})\n",
    "   \n",
    "    def predict(self, initial_input, num_pred,sess_number = -1):\n",
    "        \"\"\"\n",
    "        predicts num_pred characters based on the provided string, initial_input, using the multi_layer rnn at iteration\n",
    "        sess_number\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_input: String; the initial input into the rnn must be of length length_sequence - 1 and all the\n",
    "                               characters in the string must have been in the training data set\n",
    "        num_pred: Integer; number of characters you would like the rnn to predict based off of initial_input\n",
    "        sess_number: Integer; the checkpointed version of the model you would like to make \n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        accumulator: String; predicted output of the rnn\n",
    "        \"\"\"\n",
    "        def check_input():\n",
    "            \"\"\"\n",
    "            convert initial_input to binary format and ensures all the characters in\n",
    "            initial_input have been in the training data set\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            None\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            Nothing -> if length requirement or character subset conditions not met\n",
    "            Matrix -> if conditions met, will be the binarized input into the rnn\n",
    "            \"\"\"\n",
    "            bytes = map(ord, initial_input)\n",
    "            if any(map(lambda x: (x<self.rnn_tg.mn) and (x>self.rnn_tg.mx),bytes)):\n",
    "                print \"your character byte values must be between %s and %s\"%(self.rnn_tg.mn, self.rnn_tg.mx)\n",
    "            else:\n",
    "                n = len(bytes)\n",
    "                lst = [bytes]+[[0]*n]*(self.rnn_tg.mini_batch_size-1)\n",
    "                return np.vstack(map(self.rnn_tg.one_hot_map,lst)).reshape(self.rnn_tg.mini_batch_size, n, self.rnn_tg.mx-self.rnn_tg.mn+1)\n",
    "\n",
    "        def bytes_to_char(prediction):\n",
    "            \"\"\"\n",
    "            converts the byte into its character\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            prediction: Integer; byte representation of character\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            chr(byte): Character; the character representation of the given byte\n",
    "            \"\"\"\n",
    "            byte = np.argmax(prediction)+self.rnn_tg.mn\n",
    "            return chr(byte)\n",
    "\n",
    "        input_array = check_input()\n",
    "        sess_location = self.sess_list[sess_number]\n",
    "        tf.reset_default_graph()\n",
    "        inputs, _, initial_hidden, _, _, y_hat, all_hidden_states, saver = self.model.generate_model()\n",
    "        if tstRR.model.gate == \"LSTM\":\n",
    "            h = np.zeros([self.rnn_tg.mini_batch_size, 2*self.model.n_layers*self.model.h_size])\n",
    "        else:\n",
    "            h = np.zeros([self.rnn_tg.mini_batch_size, self.model.n_layers*self.model.h_size])\n",
    "        accumulator = initial_input\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            saver.restore(sess, sess_location)\n",
    "            for i in range(num_pred):\n",
    "                strt = input_array.shape[1]%self.pred_len\n",
    "                reshape_input = input_array[:,strt:,:]\n",
    "                prediction, all_h = sess.run([y_hat, all_hidden_states], feed_dict = {inputs: reshape_input, initial_hidden: h})\n",
    "                accumulator += bytes_to_char(prediction[0,-1])\n",
    "                input_array = np.append(input_array,prediction[:,-1,:].reshape(self.rnn_tg.mini_batch_size,1,self.rnn_tg.mx-self.rnn_tg.mn+1),axis=1)\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tstRR = RNN_Next_Char([\"Data/shakespeare-hamlet.txt\"],256,4, \n",
    "                      gate = \"LSTM\", len_sequence = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tstRR.train(\"/models\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tstRR.predict(\"\"\"Ham.\"\"\",12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "    - Train with all of Shakespeare\n",
    "    - Train with TensorFlow Repository\n",
    "    - Train using GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Python Tale builds on what Karpathy started.  This notebook provides the code and examples to build a multilayer rnn(using the scan function) using either LSTM, GRU or ELMAN gates to predict characters at every nth time step. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
